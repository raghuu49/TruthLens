{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7887ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac84042",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import sys\n",
    "\n",
    "# Increase field size limit\n",
    "csv.field_size_limit(sys.maxsize)\n",
    "\n",
    "# Now read the large CSV safely\n",
    "df = pd.read_csv('/content/WELFake_Dataset.csv', skip_blank_lines=True, engine='python')\n",
    "df.head()\n",
    "df=df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f0c792",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.drop('label',axis=1)\n",
    "y=df['label']\n",
    "X,y\n",
    "X.shape,y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa371210",
   "metadata": {},
   "source": [
    "Installing Required Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6263f93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.text import one_hot\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b8574f",
   "metadata": {},
   "outputs": [],
   "source": [
    "voc_size=5000\n",
    "messages=X.copy()\n",
    "messages['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737504dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "messages = messages.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9a97a1",
   "metadata": {},
   "source": [
    "Preprocessing Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89dfa12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "ps = PorterStemmer()\n",
    "corpus = []\n",
    "\n",
    "for i in range(0, len(messages)):\n",
    "    review = re.sub('[^a-zA-Z0-9]', ' ', messages['title'][i])  # fixed regex\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    review = [ps.stem(word) for word in review if word not in stop_words]\n",
    "    review = ' '.join(review)  # fixed join\n",
    "    corpus.append(review)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d69834",
   "metadata": {},
   "source": [
    "One hot representation and padding to make the sequence equal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ff49e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "onehot_repr=[one_hot(words,voc_size) for words in corpus]\n",
    "onehot_repr\n",
    "max_length=30\n",
    "padded_title=pad_sequences(onehot_repr,padding='pre',maxlen=max_length)\n",
    "padded_title[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3585575b",
   "metadata": {},
   "source": [
    "Creating Embedding layer and LSTM-RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989dc423",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras import regularizers\n",
    "embedded_features=40\n",
    "model=Sequential()\n",
    "model.add(Embedding(voc_size,embedded_features,input_length=max_length))\n",
    "model.add( LSTM(64,return_sequences=True) )\n",
    "model.add(Dropout(0.3))\n",
    "model.add(LSTM(32))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(1,activation='sigmoid',kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "683566c3",
   "metadata": {},
   "source": [
    "Implemeting early stopping and reduceLR to stop overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47307d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=5,\n",
    "    min_lr=1e-6,\n",
    "    verbose=1\n",
    ")\n",
    "early_stopping=tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    min_delta=0.0001,\n",
    "    patience=20,\n",
    "    verbose=1,\n",
    "    mode=\"auto\",\n",
    "    baseline=None,\n",
    "    restore_best_weights=True,\n",
    "    start_from_epoch=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7030003",
   "metadata": {},
   "source": [
    "channging x and y to numpy arrays and preprocessing using sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79d35fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X_final=np.array(padded_title)\n",
    "y_final=np.array(y)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X_final,y_final,test_size=0.33,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b3a837",
   "metadata": {},
   "source": [
    "Model training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc65a7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1=model.fit(X_train,y_train,epochs=40,batch_size=64,callbacks=[early_stopping,reduce_lr],validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a96f3e6",
   "metadata": {},
   "source": [
    "Plots for model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d610e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(model_1.history['accuracy'])\n",
    "plt.plot(model_1.history['val_accuracy'])\n",
    "plt.title('accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train','test'],loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8bdbefd",
   "metadata": {},
   "source": [
    "Metrices for checking the performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80db4476",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=model.predict(X_test)\n",
    "y_pred=(y_pred>=0.5)\n",
    "from sklearn.metrics import accuracy_score\n",
    "score=accuracy_score(y_pred,y_test)\n",
    "score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm=confusion_matrix(y_test,y_pred)\n",
    "cm\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa4edd6a",
   "metadata": {},
   "source": [
    "Saving the model for further use and transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976665d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('fake_news_model1.keras')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
